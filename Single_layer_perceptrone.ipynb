{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining structure\n",
    "\n",
    "num_units = 1\n",
    "num_input = 30\n",
    "num_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining placeholders for inputs and outputs\n",
    "x = tf.placeholder(tf.float32, [None, num_input])\n",
    "y = tf.placeholder(tf.float32, [None, num_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining weights and bias\n",
    "\n",
    "weight = tf.Variable(tf.random_normal([num_input, num_units]))\n",
    "bias = tf.Variable(tf.random_normal([num_units]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining activation function i.e sigmoid(XW + b)\n",
    "\n",
    "output = tf.add(tf.matmul(x,weight),bias)\n",
    "output = tf.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss/cost function\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining optimizer\n",
    "\n",
    "gradient_opt = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking global initializer to initiase all variables defined above\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X,Y,batch_size,idx):\n",
    "    return X[batch_size*idx:batch_size*(idx+1)],Y[batch_size*idx:batch_size*(idx+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[0:500]\n",
    "y_train = y_train[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.7032617497444151\n",
      "Epoch 2 Loss 0.7032617497444151\n",
      "Epoch 3 Loss 0.7032617497444151\n",
      "Epoch 4 Loss 0.7032617497444151\n",
      "Epoch 5 Loss 0.7032617497444151\n",
      "Epoch 6 Loss 0.7032617497444151\n",
      "Epoch 7 Loss 0.7032617497444151\n",
      "Epoch 8 Loss 0.7032617497444151\n",
      "Epoch 9 Loss 0.7032617497444151\n",
      "Epoch 10 Loss 0.7032617497444151\n",
      "Epoch 11 Loss 0.7032617497444151\n",
      "Epoch 12 Loss 0.7032617497444151\n",
      "Epoch 13 Loss 0.7032617497444151\n",
      "Epoch 14 Loss 0.7032617497444151\n",
      "Epoch 15 Loss 0.7032617497444151\n",
      "Epoch 16 Loss 0.7032617497444151\n",
      "Epoch 17 Loss 0.7032617497444151\n",
      "Epoch 18 Loss 0.7032617497444151\n",
      "Epoch 19 Loss 0.7032617497444151\n",
      "Epoch 20 Loss 0.7032617497444151\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "batch_size=20\n",
    "total_batch_count=x_train.shape[0]/batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epochs):\n",
    "        avg_loss=0\n",
    "        for i in range(int(total_batch_count)):\n",
    "            batch_x,batch_y=get_batch(x_train,y_train,batch_size,i)\n",
    "            _,c=sess.run([gradient_opt,loss],feed_dict={x:batch_x,y:batch_y})\n",
    "            avg_loss+=c/total_batch_count\n",
    "        print(\"Epoch\",e+1,'Loss',avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is constant hence we need to look at out activation function and our learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
